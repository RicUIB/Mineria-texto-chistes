---
title: "Ayuda la asignación de preferencia colas exploración radiológica basada en analisis textual de la petición"
author: "Irene & Ricardo"
date: "19/2/2021"
output: 
  html_document: 
    toc: yes
    number_sections: yes
    df_print: kable
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,cache=TRUE)
library(tidyverse)
```

# Primera aproximacion de NLP para el análisis de las peticiones radiaológicas


##  Carga de datos




```{r}
data_raw=read_delim("data_raw.csv",delim = ";",col_names = FALSE)
str(data_raw)
knitr::kable(head(data_raw,20))
text=data_raw$X2
table(unlist(lapply(text,FUN=function(x) Encoding(x))))
head(text)
library(dplyr)
text_df <- tibble(line = 1:length(text), text_raw =text)%>% mutate(Enconding=Encoding(text_raw),text_utf8=enc2utf8(text))
```


## Extracción del diccionario raw empírico desde los diagnosticos

Extraemos el dic_raw_radio_1 todas las palabras que aparecen  con separación   espacio. 

Criterios iniciales:

* Decidimos enconding a UTF-8  columna  text_utf8 si hay que depurar por enconding habrá que ver cómo.
* Hay que decidir qué se hace con los CARACTERES SPECIALES:{,:; () ¿?!!}. De momento los voy a eliminar 
* Todas las MAYÚSCULAS a MINÚSCULAS
* De momento NO SE ELIMINAN DIGITOS: se quedan tal cual, hay que distinguir los de los dígitos de años.
* No catalogamos idiomas....  se supone que todo está en castellano o términos técnicos que añadiremos
* Castellano es toda palabra o   derivado de palabra que se encuentre en un spelling standar de castellano que podemos ir adaptando.




```{r}
library(tidytext)
glimpse(text_df)
text_raw=text_df %>% unnest_tokens(word, text_utf8)
text_raw
glimpse(text_raw)
dic_raw_radio_1=sort(unique(text_raw$word))
nw=length(dic_raw_radio_1)# Hay 1627 palabras
nw
```

## Construcción del modelo de diccionario

Construiremos una tabla de modelado del corpus de palabras de diagnosis:

* Como primary key la word ( las `nw` words) (desde el text_rawutf8)
* Su frecuencia: número de veces que  aparece en los  diagnósticos
* Si es correcta  según un spelling de español  de España (hay que buscar... qué hay mejor)

```{r}
count_freq=text_raw %>% group_by(word) %>% summarise(N=n())

dic_raw_radio_1 = tibble(word=dic_raw_radio_1) %>% left_join(count_freq,by="word")
```


Ahora vemos claramente cómo podemos mejorar las words para UNIFICARLAS en un único "léxico" que nos permita un tratamiento del nivel de urgencia

Una ejemplos


Palabras que contienen "zq"

```{r}
dic_raw_radio_1[grep("zq",dic_raw_radio_1$word),]
```


Palabras que  contienen "ch"

```{r}
dic_raw_radio_1[grep("(ch)",dic_raw_radio_1$word),]
```


Palabras (dos palabras) con :

```{r}
dic_raw_radio_1[grep(":",dic_raw_radio_1$word),]
```
### Añadimos columna  de spelling al diccionario



Primero veamos algunos ejemplos de las sugerencias

```{r}
library("spelling")
library("hunspell")
#https://github.com/titoBouzout/Dictionaries # do
es=dictionary(lang = "es_ES", affix = NULL, add_words = NULL,
  cache = TRUE)
list_dictionaries()
hunspell_check(c("bieja","colon","colón"),dic= "es_ES")

hunspell_suggest(c("bieja","colon","colón"),dic="es_ES")
```

de momento tomaremos  sólo la primera sugerencia, aunque guardaremos todas.



```{r}
list_sugerences= sapply(dic_raw_radio_1$word, FUN=function(x) hunspell_suggest(x,dic="es_ES"))



dic_raw_radio_1$list_sugerence_first=sapply(list_sugerences, FUN=function(x) x[1])
dic_raw_radio_1$list_sugerence_all=sapply(list_sugerences,
                                          FUN=function(x){
                                            if(length(x)>=1) {return(paste(x,collapse=","))}
                                            if(length(x)==0){return(NA)}
                                            })
glimpse(dic_raw_radio_1)
```


# Primer modelo de curado de las peticiones



```{r}
knitr::kable(head(dic_raw_radio_1,20))
```


### Salvar en excel 



```{r}
write_excel_csv2(x=dic_raw_radio_1,file="dic_raw_radio_1_2.csv")
```


```{r}
dic_raw_radio_1_long_peticion = dic_raw_radio_1 %>% right_join(text_raw,by="word")

write_excel_csv2(x=dic_raw_radio_1_long_peticion,file="dic_raw_radio_1_2_long_peticion.csv")
```


## Siguiente paso tratamineto de los datos curados y generación de las Document Term Matrix


Primera aproximación generación dela DTM del corpus de peticiones curadas. Cruzar estos datos con las prioridades.

```
DTM=table(text_df$line,text_df$word)# Document Text Matrix
sum(DTM)
colSums(DTM)
row_sums(DTM)
```


